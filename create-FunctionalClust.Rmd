---
title: "Creating the ``r params$package_name`` R package"
author: "Your Name"
date: "The Date"
knit: litr::render
output: litr::litr_html_document
params:
  package_name: "FunctionalClust"
  package_parent_dir: "." # <-- relative to this file's location
---

<!-- This Rmd file contains all the code needed to define an R package.  Press "Knit" in RStudio or more generally run `litr::render("name-of-this-file.Rmd")` to generate the R package.  Remember that when you want to modify anything about the R package, you should modify this document rather than the package that is outputted.
-->

## Package setup

We start by specifying the information needed in the DESCRIPTION file of the R package.

```{r package-setup, message=FALSE, results='hide'}
usethis::create_package(
  path = ".",
  fields = list(
    Package = params$package_name,
    Version = "0.0.0.9000",
    Title = "A Package That Says Hello",
    Description = "This package says hello.  But its actual purpose is to show how an R package can be completely coded in a single R markdown file.",
    `Authors@R` = person(
      given = "First",
      family = "Last",
      email = "you@gmail.com",
      role = c("aut", "cre")
      )
  )
)
usethis::use_mit_license(copyright_holder = "F. Last")
```

## Now to the package itself

### Define a function

Helper function that prepare data and label from a dataframe with label in the last column.
```{r}
#' Split a data frame into a data-matrix and indexed label table
#'
#' @param df A data.frame with (n + 1) columns:
#'           the first n are numeric predictors,
#'           the last column is a (possibly-NA) character/ factor label.
#' @return   A list with two elements:
#'           • data   – an n-column numeric matrix  
#'           • labels – a data.frame with  
#'               - index  : row numbers of the non-NA labels  
#'               - label  : integer codes (factor levels) of those labels
#' @export
prepare_data <- function(df) {
  stopifnot(is.data.frame(df), ncol(df) >= 2)

  ## predictors → numeric matrix  (drop = FALSE keeps matrix form for n = 1)
  X <- as.matrix(df[, -ncol(df), drop = FALSE])

  ## labels  → (index, integer-factor)
  y        <- df[[ncol(df)]]
  y[y == "unknown"] <- NA
  idx      <- which(!is.na(y))           # rows that *have* a label
  y_factor <- factor(y[idx])             # gives reproducible level ordering
  y_int    <- as.integer(y_factor)       # integer codes 1, 2, …

  labels <- data.frame(index = idx,
                       label = y_int)

  ## keep the mapping so you can recover the original text
  attr(labels$label, "levels") <- levels(y_factor)

  list(data = X,
       labels = labels)
}

```

Helper function of row softmax
```{r}
#' Row normalized a matrix with sum up to one
#' @param log_mat
row_softmax <- function(log_mat) {
  row_max <- apply(log_mat, 1, max)
  exp(log_mat - row_max) / rowSums(exp(log_mat - row_max))
}

```

Gaussian Kernel function
```{r}
#' Row normalized a matrix with sum up to one
#' @param x
#' @param x_prime
#' @param sigma
gaussian_kernel <- function(x, x_prime, sigma = bandwidth) {
    exp(-((x - x_prime)^2) / (2 * sigma^2))
}
```


Main function
```{r}
#' Main function of semi-supervised functional clustering
#' 
#' @param data Data in matrix form(n * p). Can be the data result from prepare_data
#' @param label Label set. Can be the label result from prepare_data
#' @param num_clust Number of cluster. If not specified, will equal to number of distinct label
#' @param bandwidth Smooth bandwidth
#' @param max_iter Maximum iteration
#' @param min_gap Minimum difference of likelihood
#' @param nrep Number of repetitions
#' @return A list with three elements:
#'           • data   – an n-column numeric matrix  
#'           • labels – a data.frame with  
#'               - index  : row numbers of the non-NA labels  
#'               - label  : integer codes (factor levels) of those labels  
#' @export
functional_cluster <- function(data , label = NULL , num_clust ,
                               bandwidth = 1, max_iter = 1000 ,
                               min_gap   = 1 , nrep      = 5) {
  n  <- nrow(data)
  p  <- ncol(data)
  K  <- num_clust
  data_matrix <- as.matrix(data)
  
  ## pre-compute Gaussian kernel over column indices (1:p)
  t_index <- seq_len(p)
  kernel_gauss <- exp(-outer(t_index, t_index, "-")^2 / (2 * bandwidth^2)) 
  
  ## identity kernel for the variance (0-1 kernel)
  kernel_id <- diag(p)                          #  p × p
  
  likeli_all <- vector("list", nrep)
  result     <- vector("list", nrep)
  
  for (r in seq_len(nrep)) {
    loglikeli_total <- numeric(max_iter)
    resp  <- gtools::rdirichlet(n, rep(1, K))     #  n × K
    rho   <- colSums(resp)/sum(resp)  #  K
    mu    <- matrix(0,  K, p)                     #  K × p
    sigma <- matrix(0.1, K, p)                    #  K × p
    
    if (!is.null(label)) {
      for (lab in unique(label$label)) {
        rows <- label[label$label == lab, ]$index
        mu[lab, ]    <- colMeans(data_matrix[rows, , drop = FALSE])
        sigma[lab, ] <- apply(data_matrix[rows, , drop = FALSE], 2, sd)
      }
    }
    # randomise the remaining components (if any)
    unfilled <- setdiff(seq_len(K), unique(label$label))
    for (i in unfilled) {
      rand <- sample(setdiff(1:n,label$index),10)
      mu[i, ]    <- colMeans(data_matrix[rand, , drop = FALSE])
      sigma[i, ] <- apply(data_matrix[rand, , drop = FALSE], 2, sd)
    }

    for (iter in seq_len(max_iter)) {
      log_resp <- matrix(0, n, K) # n × K
      
      #### E step ####
      for (k in seq_len(K)) {
        # n × p matrix of log-densities for component k
        log_dens_k <- dnorm(data_matrix,
                            mean = matrix(mu[k, ], nrow = n, ncol = p, byrow = TRUE),
                            sd   = matrix(sigma[k, ], nrow = n, ncol = p, byrow = TRUE),
                            log  = TRUE)
        log_resp[ , k] <- log(rho[k]) + rowSums(log_dens_k)
      }
      resp <- row_softmax(log_resp) # n × K
      
      if (!is.null(label)) {
        anchored <- label$index
        classes  <- label$label
        resp[anchored, ] <- 0
        resp[cbind(anchored, classes)] <- 1
      }
      
      
      #### M step ####
      rho <- pmax(colMeans(resp), 1e-10) # K, pmax avoid log(0)
      
      for (k in seq_len(K)) {
        w_k           <- resp[ , k]                # n
        w_sum         <- sum(w_k) + 1e-8  # 1 × p
        numer_mu      <- (t(w_k) %*% data_matrix) %*% kernel_gauss
        denom         <- w_sum * colSums(kernel_gauss)
        mu[k, ]       <- numer_mu / pmax(denom, 1e-2)
      }
      
      for (k in seq_len(K)) {
        centered      <- sweep(data_matrix, 2, mu[k, ], "-")  # n × p
        numer_sig     <- colSums(resp[ , k] * centered^2)
        sigma[k, ]    <- sqrt(pmax(numer_sig / pmax(colSums(resp)[k], 1e-2), 1e-5))
      }
      
      loglikeli_total[iter] <- sum(rowSums(resp * (log_resp - log(pmax(resp, 1e-10)))))
      

      if (iter > 1 && abs(loglikeli_total[iter] - loglikeli_total[iter - 1]) < min_gap){
        break
      }
    }
    
    likeli_all[[r]] <- loglikeli_total[seq_len(iter)]
    result[[r]]     <- list(mu = mu, sigma = sigma, rho = rho, resp = resp)
  }
  
  best_time <- which.max(sapply(likeli_all, max, na.rm = TRUE))
  likeli_trace = likeli_all[[best_time]]
  
  list(likeli_trace = likeli_trace,
       result       = result[[best_time]],
       likelihood   = likeli_trace[length(likeli_trace)])
}
```


Prediction function
```{r}
#' Make prediction on result$resp
#' @param resp The n*K memebership matrix generate from functional_cluster. It is in res$result$resp
#' @return A dataframe with the first column is predictive label and the second colunm is proability
#' @export
prediction <- function(res){
  pred <- data.frame(t(apply(res$result$resp, 1, function(p) {
    k <- sample.int(length(p), size = 1, prob = p)
    c(predict_label = k, prob = p[k])})))
  return(pred)
}
```


### Create a dataset

In this case, we'll create the data from scratch.  However, we can also download data from a different source here.

```{r}
#data <- read.csv("../data/combined_proteindata_loadingnorm_imputed_rownorm_20240617.csv" , row.names = 1)
#label_data <- read.csv("../data/annotationsforlopit_20240813.csv")
#full_data <- left_join(tibble::rownames_to_column(data),label_data,by=c("rowname"="protein_id"))

yeast2018 <- read.csv("../../data/yeast2018.csv",row.names = 1)
hirst2018 <- read.csv("../../data/hirst2018.csv",row.names = 1)
moloneyTbBSF <- read.csv("../../data/moloneyTbBSF.csv",row.names = 1)
lopitdcU2OS2018 <- read.csv("../../data/lopitdcU2OS2018.csv",row.names = 1)
E14TG2aR <- read.csv("../../data/E14TG2aR.csv",row.names = 1)
Loay2024 <- read.csv("../../data/Loay2024.csv",row.names = 1)

```

Now, let's send this off to the package:

```{r}
usethis::use_data(yeast2018,hirst2018,moloneyTbBSF,lopitdcU2OS2018,E14TG2aR,Loay2024)
```

And we'll need to document the dataset as well:


### Choosing the best hyper-parameters
```{r}
#' Cross validation to choose the best h_0
#' 
#' @param data Data in matrix form(n * p). Can be the data result from prepare_data
#' @param label Label set. Can be the label result from prepare_data
#' @param grid Grid values of bandwidth h
#' @param num_clust Number of cluster. If not specified, will equal to number of distinct label
#' @param bandwidth Smooth bandwidth
#' @param max_iter Maximum iteration
#' @param min_gap Minimum difference of likelihood
#' @param nrep Number of repetitions
#' @return A list with three elements:
#'           • all_lost – a list contains all the lost at all grid  
#'           • average_lost – average lost at all grid  
#'           • best_h – the best bandwidth
#' @export
cv_functional_clust <- function(data , label , grid = seq(0.1,2.5,0.1), num_clust , max_iter = 1000, min_gap = 0.1, nrep = 10){
  cv_all <- vector("list", length(grid))
  for(i in 1:length(grid)){
    h <- grid[i]
    p <- dim(data)[2]
  
    cv <- rep(0,p)
    for(j in 1:p){
      res <- functional_cluster(data[,-j] ,label = label, num_clust = num_clust , bandwidth = h ,max_iter = max_iter , min_gap = min_gap ,nrep = nrep)
      
      # mu_hat_(-j)(j)
      mu_hat <- res$result$mu %*% gaussian_kernel(seq(1,p,1)[-j],j,h) / sum(gaussian_kernel(seq(1,p,1)[-j],j,h))
      # gamma*y_j
      mu_tru <- t(res$result$resp) %*% as.matrix(data[,j])/colSums(res$result$resp)
      # variance
      sigma_sq_tru <- diag(t(res$result$resp) %*% sweep(matrix(rep(c(data[,j]),8),ncol=8,byrow=FALSE), 2, mu_tru,"-")^2/colSums(res$result$resp))
      # error
      cv[j] <- sum((mu_hat-mu_tru)^2/sigma_sq_tru)
    }
    cv_all[[i]] <- cv
  }
  
  # a list contain number of grids' vectors. Each vector contain number of channels errors.
  return(list(all_lost = cv_all , average_lost = lapply(cv_all,mean), best_h = grid[which.min(lapply(cv_all,mean))]))
}
```


### Visualization
```{r}
#' 
#' @param data Data
#' @param label Label
#' @param prediction Generate from prediction function 
#' @export
visualize_res <- function(data,label,res){
  pred <- prediction(res)
  
  d.umap <- umap::umap(data,n_neighbors = 500, min_dist = 0.05, 
                 verbose = T, n_epochs = 1000, n_components=2)
  scores <- data.frame(d.umap$layout)
  
  colnames(scores) <- c("x1","x2")
  data = data %>% 
    cbind(scores) %>%
    cbind(pred)
  
  new_group <- paste0( "New", seq_len( length(unique(pred$predict_label)) - length(unique(label[,2])) ) ) 
  levels <- c(attr(label$label, "levels"), new_group)
  
  p1 <- data %>% ggplot() +
  geom_point(data = data[-label[,1],], # unlabeled
             aes(x = x1, y = x2), size=1, alpha = 0.1) +
  geom_point(data = data[label[,1],], # labeled
             aes(x = x1, y = x2, col = levels[label[,2]] ), size=1.5, alpha = 0.8) +
  theme_classic() +
  theme(legend.title = element_blank(),
        plot.subtitle = element_text(hjust = 0.5),
        panel.grid.major = element_line(color = "gray88", size = 0.2)
        ) +
  labs(subtitle = "Annotated data set")
  
  p2 <- data %>% 
  ggplot() +
  geom_point(aes(x = x1, y = x2, col = levels[predict_label], size = prob) , alpha = .8) +
  scale_size(range = c(0.01, 1.5)) +
  labs(color = "", size = "Probability") +
  theme_classic() +
  theme(plot.subtitle = element_text(hjust = 0.5),
        legend.spacing.y = unit(0.05, 'cm'),
        legend.margin = margin(0, 0, 0, 0),
        panel.grid.major = element_line(color = "gray88", size = 0.2)
        ) +
  labs(subtitle = "Predictive groups")
  
  p1 / p2
}
```


Draw high probability bands
```{r}
#' 
#' @param res Output from functional_cluster
#' @param alpha Alpha level, default is 0.05
#' @param label Label set, used to assign graph titles. Can be empty(default)
#' 
#' @export
draw_hpb <- function(res, alpha = 0.05,label = NULL){
  K <- nrow(res$result$mu)
  p <- ncol(res$result$mu)
  
  if(!is.null(label)){
    group <- attr(label$label,"levels")
    if(K>length(group)){
      group <- c(group,paste0("New", 1: (K - length(group))))
    }
  }else{
    group <- paste0("Group",1:K)
  }
  
  for(i in 1:K){
    mean_line <- res$result$mu[i,]
    var_all <- res$result$sigma[i,]
    x <- seq(1,p)
    par(mgp = c(3, 0.5, 0)) 
    plot(x, t(mean_line), type = "l", ylim = c(0,1),lty = 1, lwd = 2, pch = 20, col = i,
         xlab = "", ylab = "",main = group[i])
    upper <- mean_line + qnorm(1 - (1-(1-alpha)^(1/11))/2,0,1) * var_all
    lower <- mean_line - qnorm(1 - (1-(1-alpha)^(1/11))/2,0,1) * var_all
    polygon(c(x, rev(x)), c(upper, rev(lower)), col = adjustcolor(i, alpha.f = 0.2), border = NA)
    
  }
}
```



### Testing

Let's write some tests to make sure the function behaves as desired:

```{r}
#testthat::test_that("functional clustering work", {
#  testthat::expect_equal(say_hello("Jacob"), "Hello Jacob!")
#  testthat::test
#})
train_data <- prepare_data(Loay2024)
res <- functional_cluster(data = train_data$data, label = train_data$labels, num_clust = 8 , bandwidth = 1.5, max_iter = 1000, min_gap = 0.1, nrep = 10)

#cv_functional_clust(data = train_data$data, label = train_data$labels, grid = seq(1,1.5,0.1),num_clust=8,max_iter = 1000, min_gap = 0.1, nrep = 10)

#pre_res <- prediction(res$result$resp)

#visualize_res(data = train_data$data, label = train_data$labels , res = res)

draw_hpb(res, alpha = 0.05)

```

Code chunks that have one or more lines starting with `test_that(` (or `testthat::test_that(`) are added to the package as tests.









## Documenting the package and building

We finish by running commands that will document, build, and install the package.  It may also be a good idea to check the package from within this file.

```{r}
litr::document() # <-- use instead of devtools::document()
devtools::build()
#devtools::install()
#devtools::check(document = FALSE)
```





### Add a README

Our README.Rmd lives in the `source-files` directory.  As described [here](https://pkgdown.r-lib.org/reference/build_home.html#package-logo), if we have a hex sticker, we'll add something like the following to the level-one header at the top of the README:

```
# withpkgdown: An Example Package <img src="man/figures/logo.png" align="right" height="139" />
```

We add `README.Rmd` to the package and then generate the `README.md` based on it:

```{r}
#litr::add_readme("../source-files/README.Rmd")
```



### Add a vignette

```{r}
#litr::add_vignettes("../source-files/using-package.Rmd")
```





